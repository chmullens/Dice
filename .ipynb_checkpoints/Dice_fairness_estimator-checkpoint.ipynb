{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice fairness estimator for d20 dice\n",
    "\n",
    "In this project, I estimate the likelihood that a 20-sided dice is fair. Fortunately, I had a couple of test dice: one relatively fair, and one with visible structural flaws that cause some sides to occur less often. These dice provided the test sets. \n",
    "\n",
    "There are two key outputs: an interactive visualization showing a dice's hot and cold spots, and a plot of whether a given distribution is likely to have occurred randomly. \n",
    "\n",
    "Tools: Monte Carlo methods, 3D vector math, sphere fitting\n",
    "\n",
    "I'm using Monte Carlo data simulation as the basis for the statistics, since I want to compare against a perfectly random distribution. If the specific likelihood of a one-in-a-billion event mattered, this would be a bad solution, but I'm interested in common events, so this works great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate best-approximation of \"center\" of dice. Sum up number of \n",
    "#appearances for each face, treat as length of vector aiming toward\n",
    "#that face, and sum the vectors\n",
    "\n",
    "#1. Calculate the angle to each face, relative to top peak of '1':\n",
    "#    a. Calculate spherical coordinates of each vertex\n",
    "#    b. Calculate vector to center of each face (sum vertex vectors)\n",
    "#    c. Assign numbers appropriately\n",
    "#(Averaging angles means using circular statistics, found in scipy)\n",
    "\n",
    "\n",
    "#Calculating spherical coordinates of each vertex:\n",
    "\n",
    "#From Wikipedia \"Regular Icosahedron\":\n",
    "#https://en.wikipedia.org/wiki/Regular_icosahedron#Spherical_coordinates\n",
    "#    The locations of the vertices of a regular icosahedron can be described \n",
    "#    using spherical coordinates, for instance as latitude and longitude. If \n",
    "#    two vertices are taken to be at the north and south poles (latitude ±90°),\n",
    "#    then the other ten vertices are at latitude ±arctan(1/2) ≈ ±26.57°. These \n",
    "#    ten vertices are at evenly spaced longitudes (36° apart), alternating \n",
    "#    between north and south latitudes. \n",
    "#(Implemented below)\n",
    "\n",
    "\n",
    "#Calculating vector for the center of each face:\n",
    "\n",
    "#Select the three vertices (numbered as described below) that are associated\n",
    "#with each face. Sum the cartesian vectors for each vertex, then normalize to\n",
    "#vector amplitude of one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries/functions:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import circmean \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "#OR, instead of struggling to make matplotlib do what it's not built to do,\n",
    "#I could just use plotly, which is built to handle 3D. \n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize an rng instance:\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convenience function: Convert from polar coordinates to cartesian coords\n",
    "def polar_to_cartesian(polarmat, thetatype='to_north'):\n",
    "    #polarmat format: If matrix, is rows of 3-var polar coordinates\n",
    "    #                 If list, is list of lists of 3-var polar coords\n",
    "    #                 (Probably works for list of 3-var vectors, too)\n",
    "    \n",
    "    #If it's not an array already, make it an array\n",
    "    if isinstance(polarmat, list):\n",
    "        polarmat = np.array(polarmat)\n",
    "        \n",
    "    if len(polarmat.shape)<=1:\n",
    "        one_row = True\n",
    "    else:\n",
    "        one_row = False\n",
    "    \n",
    "    #If the data doesn't include radius information, assume it's one\n",
    "    if one_row:    \n",
    "        if polarmat.shape[0]==2: \n",
    "            polarmat = np.insert(polarmat, 0, 1)\n",
    "    else:\n",
    "        if polarmat.shape[1]==2:\n",
    "            polarmat = np.insert(polarmat, 0, 1, axis=1)\n",
    "    \n",
    "    #Check the theta convention: 'to_north' or 'to_xy'\n",
    "    if thetatype=='to_north':\n",
    "        #No transformation needed:\n",
    "        polarmat = polarmat\n",
    "    elif thetatype=='to_xy':\n",
    "        #Convert theta values from \"angle from x/y plane\" to \"angle from\n",
    "        #north pole\" to fit slightly-more-standard spherical coord system\n",
    "        polarmat[:,1] = -1 * (polarmat[:,1] - pi/2)\n",
    "        \n",
    "    cartmat = np.zeros(polarmat.shape)\n",
    "    \n",
    "    if one_row:\n",
    "        cartmat[0] = polarmat[0] * np.sin(polarmat[1]) * np.cos(polarmat[2])\n",
    "        cartmat[1] = polarmat[0] * np.sin(polarmat[1]) * np.sin(polarmat[2])\n",
    "        cartmat[2] = polarmat[0] * np.cos(polarmat[1])\n",
    "    else:\n",
    "        cartmat[:,0] = polarmat[:,0] * np.sin(polarmat[:,1]) * np.cos(polarmat[:,2])\n",
    "        cartmat[:,1] = polarmat[:,0] * np.sin(polarmat[:,1]) * np.sin(polarmat[:,2])\n",
    "        cartmat[:,2] = polarmat[:,0] * np.cos(polarmat[:,1])\n",
    "    \n",
    "    return cartmat\n",
    "\n",
    "\n",
    "#Convenience function: Convert from cartesian to polar coords\n",
    "def cartesian_to_polar(cartmat, thetatype='to_north'):\n",
    "    #polarmat format: If matrix, is rows of 3-var polar coordinates\n",
    "    #                 If list, is list of lists of 3-var polar coords\n",
    "    #                 (Probably works with list of 3-var vectors, too)\n",
    "    \n",
    "    #If it's not an array already, make it an array\n",
    "    if isinstance(cartmat, list):\n",
    "        cartmat = np.array(cartmat)\n",
    "        \n",
    "    polarmat = np.zeros(cartmat.shape)\n",
    "    \n",
    "    if len(cartmat.shape)<=1:\n",
    "        one_row = True\n",
    "    else:\n",
    "        one_row = False\n",
    "    \n",
    "    #Radius:\n",
    "    if one_row:\n",
    "        polarmat[0] = np.sqrt(np.sum(np.square(cartmat)))\n",
    "        #Theta:\n",
    "        polarmat[1] = np.arccos(cartmat[2]/polarmat[0])\n",
    "        #Phi:\n",
    "        polarmat[2] = np.arctan(cartmat[1]/cartmat[0])\n",
    "    else:\n",
    "        polarmat[:,0] = np.sqrt(np.sum(np.square(cartmat), axis=1))\n",
    "        #Theta:\n",
    "        polarmat[:,1] = np.arccos(cartmat[:,2]/polarmat[:,0])\n",
    "        #Phi:\n",
    "        polarmat[:,2] = np.arctan(cartmat[:,1]/cartmat[:,0])\n",
    "    \n",
    "    #Check the theta convention: 'to_north' or 'to_xy'\n",
    "    if thetatype=='to_north':\n",
    "        #No transformation needed:\n",
    "        polarmat = polarmat\n",
    "    elif thetatype=='to_xy':\n",
    "        #Convert theta values from \"angle from x/y plane\" to \"angle from\n",
    "        #north pole\" to fit slightly-more-standard spherical coord system\n",
    "        polarmat[:,1] = -1 * (polarmat[:,1] - pi/2)\n",
    "    \n",
    "    return polarmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertex numbering (this does not make sense unless following \n",
    "#along on a dice): Start at top vertex (v1), proceed to the lower\n",
    "#right vertex of '1' (v2), proceed counterclockwise (looking down\n",
    "#at v1) through the other nine non-pole vertices (v3-v11). That \n",
    "#ends on the 'top' vertex of the upside-down 13. v11 is taken as\n",
    "#the \"zero\" point for all longitude values. Then proceed to the\n",
    "#bottom vertex (v12).\n",
    "\n",
    "at_1 = np.arctan(1/2)\n",
    "pi = np.pi\n",
    "\n",
    "#v1-v12, in order, make up 'va' (vertex angles):\n",
    "va = [[ pi/2, 0],\n",
    "      [ 1*at_1, 1*36*pi/180],\n",
    "      [-1*at_1, 2*36*pi/180],\n",
    "      [ 1*at_1, 3*36*pi/180],\n",
    "      [-1*at_1, 4*36*pi/180],\n",
    "      [ 1*at_1, 5*36*pi/180],\n",
    "      [-1*at_1, 6*36*pi/180],\n",
    "      [ 1*at_1, 7*36*pi/180],\n",
    "      [-1*at_1, 8*36*pi/180],\n",
    "      [ 1*at_1, 9*36*pi/180],\n",
    "      [-1*at_1, 10*36*pi/180],\n",
    "      [-pi/2, 0]\n",
    "     ]\n",
    "\n",
    "#Convert vertices to cartesian for use later:\n",
    "va_cart = polar_to_cartesian(va, thetatype='to_xy')\n",
    "\n",
    "#Collect vertices associated with each face (f1-f20)\n",
    "fa_raw = [[va[0], va[1], va[9]],   #1\n",
    "                   [va[6], va[8], va[11]],  #2\n",
    "                   [va[0], va[3], va[5]],   #3\n",
    "                   [va[2], va[10], va[11]], #4\n",
    "                   [va[8], va[9], va[10]],  #5\n",
    "                   [va[2], va[3], va[4]],   #6\n",
    "                   [va[0], va[7], va[9]],   #7\n",
    "                   [va[4], va[5], va[6]],   #8\n",
    "                   [va[1], va[2], va[3]],   #9\n",
    "                   [va[5], va[6], va[7]],   #10\n",
    "                   [va[1], va[2], va[10]],  #11\n",
    "                   [va[6], va[7], va[8]],   #12\n",
    "                   [va[1], va[9], va[10]],  #13\n",
    "                   [va[2], va[4], va[11]],  #14\n",
    "                   [va[7], va[8], va[9]],   #15\n",
    "                   [va[3], va[4], va[5]],   #16\n",
    "                   [va[0], va[5], va[7]],   #17\n",
    "                   [va[8], va[10], va[11]], #18\n",
    "                   [va[0], va[1], va[3]],   #19\n",
    "                   [va[4], va[6], va[11]]   #20\n",
    "                  ]\n",
    "#Convert to 20x3x2 array (face, vect, theta/phi)\n",
    "fa_raw = np.array(fa_raw)\n",
    "\n",
    "#Build the vector version:\n",
    "fv_pre = np.zeros([20,3,3])\n",
    "for n in range(3):\n",
    "    fv_pre[:,n,0:3] = polar_to_cartesian(fa_raw[:,n,:], thetatype='to_xy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = np.sum(fv_pre, axis=1)\n",
    "vect_len = np.sqrt(np.sum(np.square(fv), axis=1)) \n",
    "#All vectors should have identical length at this point, but\n",
    "#left \"vect_len\" a vector for easy inspection. \n",
    "fv = np.divide(fv, vect_len[0])\n",
    "\n",
    "# #Double-check vector lengths (should be 1):\n",
    "# np.sqrt(np.sum(np.square(fv), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SANITY CHECK: Plot the face centers. VERIFIED.\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# fig = plt.figure(figsize=[10,10])\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# for n in range(20):\n",
    "#     ax.plot(xs=[fv[n,0],fv[n,0]], ys=[fv[n,1],fv[n,1]], zs=[-1,fv[n,2]], \n",
    "#             marker='x', color='gray', linestyle='--')\n",
    "#     ax.plot(xs=[0,fv[n,0]], ys=[0,fv[n,1]], zs=[0,fv[n,2]],\n",
    "#             marker='s', linestyle='-')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input a set of dice rolls. Get the frequency of each number, \n",
    "#then just multiply the frequency vector by the array vector\n",
    "#and sum it together to get the average vector that the dice\n",
    "#favors! Now that we have the 'fv' vector, it's super simple.\n",
    "\n",
    "#Use an example set:\n",
    "test_dice = pd.read_excel('Dice_test.xlsx')\n",
    "test_dice_2 = pd.read_excel('Dice_test_2.xlsx', names=['Red','Aquamarine','Black','Purple'])\n",
    "# test_dice = test_dice[['Orange:','Blue:']]\n",
    "\n",
    "#Example test analysis:\n",
    "test_set = test_dice.iloc[:, 1]\n",
    "test_hist, test_bins = np.histogram(test_set, bins=np.arange(0.5,21.5))\n",
    "\n",
    "#This line is the key: Multiply the face vectors matrix by the\n",
    "#frequency vector. Gives you the next XYZ vector, then scale it\n",
    "#to the total number of rolls. \n",
    "outvec = np.matmul(test_hist.T, fv)/len(test_set)\n",
    "\n",
    "num_str = [str(tempnum) for tempnum in range(1,21)]\n",
    "ov_mag = np.sqrt(np.sum(np.square(outvec)))\n",
    "ov_big = outvec/ov_mag\n",
    "\n",
    "print('In this set, the dice tended toward: \\n' + str(outvec))\n",
    "if ov_mag < 0.05:\n",
    "    print('This is a relatively small bias, magnitude {0:.3f}'.format(ov_mag))\n",
    "else:\n",
    "    print('This is a relatively large bias, magnitude {0:.3f}'.format(ov_mag))\n",
    "text_outind = np.argmax(np.matmul(fv, outvec))\n",
    "print('\\nThe bias vector points toward dice face ' + num_str[text_outind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSUMPTION: Any weight bias will result in an offset of likelihood\n",
    "#between the different numbers, and that offset approximates a sphere. \n",
    "\n",
    "#GOAL: Fit a sphere to the frequency vectors. \n",
    "#The idea here is to see how closely a sphere fits the data. If the\n",
    "#fit is poor, it's likely that any bias you're seeing is due to random\n",
    "#chance, or possibly small variations in the surface of the dice. Any\n",
    "#ellipsoid would probably also work, it's not clear to me that a sphere\n",
    "#is the optimal shape, but should approximate it reasonably well. Any \n",
    "#systematic error that DOES have a good sphere fit is likely to reflect\n",
    "#a weight imbalance.\n",
    "\n",
    "#Alternative: Could also achieve a similar end goal by testing a simple\n",
    "#correlation of how often the values for adjacent sides are similar. \n",
    "\n",
    "#Alternative 2: Could calculate \"slope\" from the direction pole to the\n",
    "#counter pole in roughly 6 directions, test slope fit. \n",
    "\n",
    "#If I wanted to get VERY fancy, I could simulate the effects of change\n",
    "#in the center of mass with a physics engine, but that's overkill.\n",
    "\n",
    "#Sphere:\n",
    "#Basic equation: (x+x0)^2 + (y+y0)^2 + (z+z0)^2 = R^2\n",
    "#Fitting variables: x0, y0, z0, R\n",
    "#Cost: (x+x0)^2 + (y+y0)^2 + (z+z0)^2 - R^2 (minimize radial distance)\n",
    "#I'd rather not do the partial derivatives and gradient myself, so I'm \n",
    "#cribbing the math from a MATLAB implementation of sphere fitting:\n",
    "\n",
    "#https://www.mathworks.com/matlabcentral/fileexchange/34129-sphere-fit-least-squared\n",
    "\n",
    "#which uses a normal equation solution. \n",
    "\n",
    "#Matlab code:\n",
    "# A=[mean(X(:,1).*(X(:,1)-mean(X(:,1)))), ...\n",
    "#     2*mean(X(:,1).*(X(:,2)-mean(X(:,2)))), ...\n",
    "#     2*mean(X(:,1).*(X(:,3)-mean(X(:,3)))); ...\n",
    "#     0, ...\n",
    "#     mean(X(:,2).*(X(:,2)-mean(X(:,2)))), ...\n",
    "#     2*mean(X(:,2).*(X(:,3)-mean(X(:,3)))); ...\n",
    "#     0, ...\n",
    "#     0, ...\n",
    "#     mean(X(:,3).*(X(:,3)-mean(X(:,3))))];\n",
    "# A=A+A.';\n",
    "# B=[mean((X(:,1).^2+X(:,2).^2+X(:,3).^2).*(X(:,1)-mean(X(:,1))));...\n",
    "#     mean((X(:,1).^2+X(:,2).^2+X(:,3).^2).*(X(:,2)-mean(X(:,2))));...\n",
    "#     mean((X(:,1).^2+X(:,2).^2+X(:,3).^2).*(X(:,3)-mean(X(:,3))))];\n",
    "# Center=(A\\B).';\n",
    "# Radius=sqrt(mean(sum([X(:,1)-Center(1),X(:,2)-Center(2),X(:,3)-Center(3)].^2,2)));\n",
    "\n",
    "#Translated to Python:\n",
    "def fit_sphere(X):\n",
    "    #Fits a sphere to a given set of Cartesian points. May fail\n",
    "    #at small numbers of points. If you're working with a small\n",
    "    #number of integer data points, like rolls, you may want to\n",
    "    #pre-process your data, since a pile of zeros does not work\n",
    "    #very well. I would recommend adding 0.05 times the vector,\n",
    "    #for example. \n",
    "    \n",
    "    #Might only need slight reworking if I wanted to try a sphere\n",
    "    #with fixed radius? Unclear. \n",
    "    \n",
    "    A = [[np.mean(X[:,0]*(X[:,0]-np.mean(X[:,0]))),\n",
    "          2*np.mean(X[:,0]*(X[:,1]-np.mean(X[:,1]))),\n",
    "          2*np.mean(X[:,0]*(X[:,2]-np.mean(X[:,2])))],\n",
    "         [0,\n",
    "          np.mean(X[:,1]*(X[:,1]-np.mean(X[:,1]))),\n",
    "          2*np.mean(X[:,1]*(X[:,2]-np.mean(X[:,2])))],\n",
    "         [0,\n",
    "          0,\n",
    "          np.mean(X[:,2]*(X[:,2]-np.mean(X[:,2])))]]\n",
    "    A = np.array(A)\n",
    "    A = A + A.T\n",
    "    B = [np.mean((X[:,0]*X[:,0] + X[:,1]*X[:,1] + X[:,2]*X[:,2]) * (X[:,0]-np.mean(X[:,0]))),\n",
    "         np.mean((X[:,0]*X[:,0] + X[:,1]*X[:,1] + X[:,2]*X[:,2]) * (X[:,1]-np.mean(X[:,1]))),\n",
    "         np.mean((X[:,0]*X[:,0] + X[:,1]*X[:,1] + X[:,2]*X[:,2]) * (X[:,2]-np.mean(X[:,2])))]\n",
    "    B = np.array(B).T\n",
    "    Center = np.linalg.lstsq(A,B, rcond=None)[0]\n",
    "    Radius = np.sqrt(np.mean(np.sum(\n",
    "        np.square(np.array([X[:,0]-Center[0],X[:,1]-Center[1],X[:,2]-Center[2]]).T), axis=1\n",
    "    )));\n",
    "    \n",
    "    return Center, Radius\n",
    "\n",
    "def sphere_error(X, Center, Radius):\n",
    "    #To calculate error, we want the distance between the\n",
    "    #sphere and the face endpoint along the face vector.\n",
    "    \n",
    "    #Calculate location on the sphere where the ratio between\n",
    "    #x, y, and z is the same as it is in the target vector:\n",
    "    \n",
    "    #Get the fixed ratio values between the elements, which \n",
    "    #allows y & z to be expressed as multiples of x:\n",
    "    yrat = X[:,1]/X[:,0] #ratio of y to x, elementwise\n",
    "    zrat = X[:,2]/X[:,0] #ratio of z to x, elementwise\n",
    "    #Plug into sphere equation, simplify to ax^2+bx+c=0:\n",
    "    a = 1 + np.square(yrat) + np.square(zrat)\n",
    "    b = 2*Center[0] + 2*yrat*Center[1] + 2*zrat*Center[2]\n",
    "    c = np.square(np.array([Center[0], Center[1], Center[2], Radius]))\n",
    "    c = c[0]+c[1]+c[2]-c[3]\n",
    "    #Ye olde Pythagorean Theorem:\n",
    "    xint1 = (-b + np.sqrt(np.square(b) - 4*a*c))/(2*a)\n",
    "    xint2 = (-b - np.sqrt(np.square(b) - 4*a*c))/(2*a)\n",
    "    \n",
    "    #Xintercept is about the X array, not the x direction.\n",
    "    Xintercept1 = np.array([xint1, yrat*xint1, zrat*xint1]).T\n",
    "    Xintercept2 = np.array([xint2, yrat*xint2, zrat*xint2]).T\n",
    "\n",
    "    #Could do this with least-squares distances, but this isn't\n",
    "    #so bad computationally. Only selecting between two points \n",
    "    #for each of 20 base coordinates.\n",
    "    #Error between each (two-element) sphere solution and X:\n",
    "    Xerror_pre = np.array([np.sum(X - Xintercept1, axis=1), np.sum(X - Xintercept2, axis=1)])\n",
    "    #Pick the smaller-amplitude of the two errors, then add \n",
    "    #the absolute values up for the whole dataset. \n",
    "    Xerror = np.sum(np.min(np.abs(Xerror_pre.T), axis=1))\n",
    "    \n",
    "    #Useful to return the raw individual-face errors:\n",
    "    tempinds = np.argmin(np.abs(Xerror_pre.T), axis=1)\n",
    "    Xerror_face = [Xerror_pre.T[n,tempinds[n]] for n in range(X.shape[0])]\n",
    "    \n",
    "    return Xerror, Xerror_face\n",
    "\n",
    "\n",
    "#Both functions are pretty efficient, run time a little under 1ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throws a variety of warnings. Would be nice to clean them up,\n",
    "#but \n",
    "\n",
    "#Pick a random subset of rolls from test_dice:\n",
    "test_set = test_dice.iloc[:,0]\n",
    "rng.shuffle(test_set.values)\n",
    "test_set = test_set[0:200]\n",
    "\n",
    "test_hist, test_bins = np.histogram(test_set, bins=np.arange(0.5,21.5))\n",
    "\n",
    "#Going to bias the histogram a tiny bit to avoid division\n",
    "#errors when using small sets of rolls. Errs VERY slightly\n",
    "#toward assuming the data is evenly distributed. \n",
    "test_hist = test_hist + 0.0001\n",
    "\n",
    "#Element-wise multiply the face vectors with how\n",
    "#many times each face was rolled\n",
    "X = (fv.T*test_hist.T).T\n",
    "\n",
    "dice_sphere = fit_sphere(X)\n",
    "\n",
    "print(dice_sphere)\n",
    "Center = dice_sphere[0]\n",
    "Radius = dice_sphere[1]\n",
    "\n",
    "Xerror = sphere_error(X, Center, Radius)\n",
    "\n",
    "print('Total error across all faces: {0:.2f} / {1} rolls'.format(Xerror[0], sum(test_hist[0:20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKES A MINUTE OR TWO TO RUN AT 10000 SETS\n",
    "\n",
    "#Let's figure out what these vectors look like with randomly-\n",
    "#distributed numbers.\n",
    "\n",
    "#It should be possible to calculate from first principles what\n",
    "#the bias should be for a given number of rolls, since we know\n",
    "#the geometry and the likelihood of each face being selected,\n",
    "#but it's much easier to do numerically since we've already got\n",
    "#the model. \n",
    "\n",
    "rng = np.random.default_rng()\n",
    "num_str = [str(tempnum) for tempnum in range(1,21)]\n",
    "\n",
    "numsets = 50000\n",
    "print_outcomes = False\n",
    "\n",
    "setsizes = [20,50,100,150,200,300,500,1000,2000,10000]\n",
    "\n",
    "\n",
    "refresh = False\n",
    "\n",
    "if refresh:\n",
    "    all_mags = np.zeros([numsets, len(setsizes)])\n",
    "    all_sphere = np.zeros([numsets, len(setsizes), 4])\n",
    "    all_error = np.zeros([numsets, len(setsizes)])\n",
    "    all_testset = np.zeros([numsets, len(setsizes), 20])\n",
    "\n",
    "    for k in range(len(setsizes)):\n",
    "        numrolls = setsizes[k]\n",
    "        for n in range(numsets):\n",
    "            test_set = rng.integers(size=[numrolls,1], high=21, low=1)\n",
    "            test_hist, test_bins = np.histogram(test_set, bins=np.arange(0.5,21.5))\n",
    "            test_hist = test_hist + 0.00001\n",
    "\n",
    "            outvec = np.matmul(test_hist.T, fv)/len(test_set)\n",
    "\n",
    "            ov_mag = np.sqrt(np.sum(np.square(outvec)))\n",
    "            if ov_mag < 0:\n",
    "                print(k, n, ov_mag)\n",
    "            ov_big = outvec/ov_mag\n",
    "\n",
    "            X = (fv.T*test_hist.T).T\n",
    "            dice_sphere = fit_sphere(X)\n",
    "            Xerror = sphere_error(X, dice_sphere[0], dice_sphere[1])\n",
    "            if print_outcomes:\n",
    "                print('In this set, the dice tended toward: \\n' + str(outvec))\n",
    "                text_outind = np.argmax(np.matmul(fv, outvec))\n",
    "                #print('The bias vector aims closest to ' + num_str[text_outind])\n",
    "                if ov_mag < 0.05:\n",
    "                    print('This is a relatively small bias, magnitude {0:.3f}'.format(ov_mag))\n",
    "                else:\n",
    "                    print('This is a relatively large bias, magnitude {0:.3f}'.format(ov_mag))\n",
    "\n",
    "            all_mags[n,k] = ov_mag\n",
    "            all_sphere[n,k,0:3] = dice_sphere[0]\n",
    "            all_sphere[n,k,3] = dice_sphere[1]\n",
    "            all_error[n,k] = Xerror[0]\n",
    "            all_testset[n,k,0:20] = test_hist\n",
    "\n",
    "    #Note: A few sqrt value warnings can happen for the smaller\n",
    "    #roll sets, could fix but doesn't cause a problem. EXPECT\n",
    "    #WARNINGS OCCASIONALLY.\n",
    "\n",
    "    #Save out the sim data:\n",
    "    np.save('./processed_variables/rollsim_all_mags',all_mags)\n",
    "    np.save('./processed_variables/rollsim_all_sphere',all_sphere)\n",
    "    np.save('./processed_variables/rollsim_all_error',all_error)\n",
    "    np.save('./processed_variables/rollsim_all_testset',all_testset)\n",
    "else:\n",
    "    #Load the sim data:\n",
    "    all_mags = np.load('./processed_variables/rollsim_all_mags.npy')\n",
    "    all_sphere = np.load('./processed_variables/rollsim_all_sphere.npy')\n",
    "    all_error = np.load('./processed_variables/rollsim_all_error.npy')\n",
    "    all_testset = np.load('./processed_variables/rollsim_all_testset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = all_mags.shape\n",
    "\n",
    "#Range data:\n",
    "set_mean = np.zeros([len(setsizes)])\n",
    "set_std = np.zeros([len(setsizes)])\n",
    "set_05 = np.zeros([len(setsizes)])\n",
    "set_95 = np.zeros([len(setsizes)])\n",
    "\n",
    "for n in range(len(setsizes)):\n",
    "    set_mean[n] = np.mean(all_mags[:,n])\n",
    "    set_std[n] = np.std(all_mags[:,n])\n",
    "    set_05[n] = np.sort(all_mags[:,n])[round(shp[0]*0.05)]\n",
    "    set_95[n] = np.sort(all_mags[:,n])[round(shp[0]*0.95)]\n",
    "    print('Mean bias vector mag/stdev, ' + str(setsizes[n]) + ' rolls per set, ' + str(numsets) + ' sets')\n",
    "    print('{0:.4f} ± {1:.4f}'.format(set_mean[n], set_std[n]))\n",
    "    print('5%-95% range: {0:.3f}-{1:.3f}'.format(set_05[n], set_95[n]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[7,7])\n",
    "ax = plt.subplot(111)\n",
    "xtemp = np.array(setsizes)\n",
    "ytemp = set_mean\n",
    "ystd = set_std\n",
    "yrange05 = set_05\n",
    "yrange95 = set_95\n",
    "ax.plot(xtemp, ytemp, 'b', \n",
    "        xtemp, ytemp+ystd, 'c--', \n",
    "        xtemp, ytemp-ystd, 'c--', \n",
    "        xtemp, yrange05, 'r--',\n",
    "        xtemp, yrange95, 'r--',\n",
    "       )\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "xtemp2 = xtemp.reshape(-1,1) #reshape to a nx1 vector (flatten)\n",
    "ytemp2 = ytemp.reshape(-1,1)\n",
    "ystd2 = ystd.reshape(-1,1)\n",
    "yrange05_2 = yrange05.reshape(-1,1)\n",
    "yrange95_2 = yrange95.reshape(-1,1)\n",
    "\n",
    "model = LinearRegression().fit(np.log(xtemp2), np.log(ytemp2))\n",
    "modelup = LinearRegression().fit(np.log(xtemp2), np.log(ytemp2+ystd2))\n",
    "modeldn = LinearRegression().fit(np.log(xtemp2), np.log(ytemp2-ystd2))\n",
    "modelup2 = LinearRegression().fit(np.log(xtemp2), np.log(yrange95_2))\n",
    "modeldn2 = LinearRegression().fit(np.log(xtemp2), np.log(yrange05_2))\n",
    "\n",
    "ax.set_title('(This is really the simulation data, yes).\\nLinear fit to mean, r^2 = {0:.7f}'.format(model.score(np.log(xtemp2), np.log(ytemp2))))\n",
    "fits_set = np.zeros([5,2])\n",
    "fits_set[0,:] = (np.concatenate([modeldn2.coef_[0], modeldn2.intercept_]))\n",
    "fits_set[1,:] = (np.concatenate([modeldn.coef_[0], modeldn.intercept_]))\n",
    "fits_set[2,:] = (np.concatenate([model.coef_[0], model.intercept_]))\n",
    "fits_set[3,:] = (np.concatenate([modelup.coef_[0], modelup.intercept_]))\n",
    "fits_set[4,:] = (np.concatenate([modelup2.coef_[0], modelup2.intercept_]))\n",
    "\n",
    "#Data is a near-perfect fit, suggesting that 1) We definitely\n",
    "#could have properly calculated the expected bias, BUT 2) The\n",
    "#numerical approximation is very good. In other words, we can\n",
    "#predict how much bias we'd expect at any number of rolls, not\n",
    "#just the tested sets. \n",
    "\n",
    "\n",
    "plt.legend(['Mean', '-1std of sets', '+1std of sets', '95% of sets', '5% of sets'])\n",
    "plt.xlabel('Number of rolls (log)')\n",
    "plt.ylabel('Bias magnitude across evenly-distributed sets (log)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_range(nrolls, fits_set):\n",
    "    \"\"\"\n",
    "    Inputs: Number of rolls, set of linear fit equations.\n",
    "    Outputs the expected range of bias vector variance, using the above\n",
    "    fit equations to extrapolate for the given number of rolls 'nrolls'\n",
    "    \"\"\"\n",
    "    biasvec_range = []\n",
    "    for n in np.arange(fits_set.shape[0]):\n",
    "        biasvec_range.append(np.exp(fits_set[n,0]*np.log(nrolls) + fits_set[n,1]))\n",
    "    \n",
    "    #The inner numbers (.05, -1 stdev) are largely useless. Only use mean,\n",
    "    #+1 stdev, or 0.95, biasvec_range[2:]. \n",
    "    \n",
    "    #Why? They assume that the data is normal, when the data is a one-sided normal,\n",
    "    #BIG difference!\n",
    "    \n",
    "    return biasvec_range[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasvec_range = bias_range(75,fits_set)\n",
    "\n",
    "#My plan was to use this value to estimate the likelihood of a given\n",
    "#bias vector for a given set of rolls was. However, because the bias \n",
    "#vector isn't as informative as I hoped, I'll be focusing on other \n",
    "#analyses. \n",
    "\n",
    "biasvec_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_range(len(test_dice), fits_set)\n",
    "\n",
    "#In other words, for the given set of rolls, you'd expect a bias\n",
    "#vector with magnitude .03, up to .05 at the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DISPLAY WITH VECTORS:\n",
    "# fig = plt.figure(figsize=[10,10])\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# for n in range(20):\n",
    "#     ax.plot(xs=[fv[n,0],fv[n,0]], ys=[fv[n,1],fv[n,1]], zs=[-1,fv[n,2]], \n",
    "#             marker='x', color='gray', linestyle='--')\n",
    "#     ax.plot(xs=[0,fv[n,0]], ys=[0,fv[n,1]], zs=[0,fv[n,2]],\n",
    "#             marker='s', linestyle='-')\n",
    "#     ax.text(x=fv[n,0], y=fv[n,1], z=fv[n,2], s=num_str[n])\n",
    "\n",
    "# ax.plot(xs=[ov_big[0],ov_big[0]], \n",
    "#         ys=[ov_big[1],ov_big[1]], \n",
    "#         zs=[-1, ov_big[2]], \n",
    "#         marker='x', color='gray', linestyle='--')\n",
    "# ax.plot(xs=[0,ov_big[0]], ys=[0,ov_big[1]], zs=[0,ov_big[2]],\n",
    "#         marker='*', markersize=15, linestyle='-', color='r')\n",
    "# ax.text(x=ov_big[0], y=ov_big[1], z=ov_big[2], s='Est. bias\\ndirection')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY THE DICE, FUNCTION\n",
    "\n",
    "def display_dice(dice_set, use_offset=True, use_offsetvec=False, cmap='rdbu_r', biasvec=False):\n",
    "    '''Outputs the relative weight of each face for a given set of rolls'''\n",
    "\n",
    "    rng.shuffle(dice_set.values)\n",
    "    test_hist, test_bins = np.histogram(dice_set, bins=np.arange(0.5,21.5))\n",
    "    outvec = np.matmul(test_hist.T, fv)/len(dice_set)\n",
    "    num_str = [str(tempnum) for tempnum in range(1,21)]\n",
    "    ov_mag = np.sqrt(np.sum(np.square(outvec)))\n",
    "    ov_big = outvec/ov_mag\n",
    "\n",
    "    #Vectors for showing the data:\n",
    "\n",
    "    #Put in the vector of points in x,y,z; then put in the\n",
    "    #point indices (i.e. point 0, point 1, etc.) that make\n",
    "    #up the individual triangles. This is basically how I \n",
    "    #built the 'fa' face angles vector in the first place,\n",
    "    #so I just copied the 'va' indices from that.\n",
    "\n",
    "\n",
    "    #Draw the shape (color for frequency of face selection):\n",
    "    tri_i = [0,6,0,2,8,2,0,4,1,5,1,6,1,2,7,3,0,8,0,4]\n",
    "    tri_j = [1,8,3,10,9,3,7,5,2,6,2,7,9,4,8,4,5,10,1,6]\n",
    "    tri_k = [9,11,5,11,10,4,9,6,3,7,10,8,10,11,9,5,7,11,3,11]\n",
    "\n",
    "    tri_int = test_hist\n",
    "\n",
    "    tri_x = va_cart[:,0]\n",
    "    tri_y = va_cart[:,1]\n",
    "    tri_z = va_cart[:,2]\n",
    "    \n",
    "    #Build the dice faces:\n",
    "    fig = go.Figure(data=[\n",
    "        go.Mesh3d(\n",
    "            x=tri_x, \n",
    "            y=tri_y, \n",
    "            z=tri_z,\n",
    "            colorscale=cmap,\n",
    "            cmax= 2*len(dice_set)/20, cmin=0,\n",
    "            #Max at double standard likelihood, \n",
    "            #min at zero for equal color weights\n",
    "            i=tri_i,\n",
    "            j=tri_j,\n",
    "            k=tri_k,\n",
    "            intensity = tri_int,\n",
    "            intensitymode = 'cell',\n",
    "            lighting=dict(ambient=1)\n",
    "        )])\n",
    "    \n",
    "    \n",
    "    #Set offset properties for all above-face markers:\n",
    "    scale_facevec = 20/len(dice_set)\n",
    "    scale_foffset = 0.9\n",
    "    \n",
    "    #Add the expected-value markers:\n",
    "    \n",
    "    #Expected value dots:\n",
    "    temp_x3 = fv[:,0]*(scale_foffset+(len(dice_set)/20)*scale_facevec)\n",
    "    temp_y3 = fv[:,1]*(scale_foffset+(len(dice_set)/20)*scale_facevec)\n",
    "    temp_z3 = fv[:,2]*(scale_foffset+(len(dice_set)/20)*scale_facevec)\n",
    "    \n",
    "    #Expected value vectors:\n",
    "    temp_x = zip(fv[:,0]*(scale_foffset+len(dice_set)/20*scale_facevec), fv[:,0]*scale_foffset, [None] * 20)\n",
    "    temp_x4 = []\n",
    "    for temptup in temp_x:\n",
    "        temp_x4 = temp_x4 + list(temptup)\n",
    "    temp_x4 = np.array(temp_x4)\n",
    "    temp_y = zip(fv[:,1]*(scale_foffset+len(dice_set)/20*scale_facevec), fv[:,1]*scale_foffset, [None] * 20)\n",
    "    temp_y4 = []\n",
    "    for temptup in temp_y:\n",
    "        temp_y4 = temp_y4 + list(temptup)\n",
    "    temp_y4 = np.array(temp_y4)\n",
    "    temp_z = zip(fv[:,2]*(scale_foffset+len(dice_set)/20*scale_facevec), fv[:,2]*scale_foffset, [None] * 20)\n",
    "    temp_z4 = []\n",
    "    for temptup in temp_z:\n",
    "        temp_z4 = temp_z4 + list(temptup)\n",
    "    temp_z4 = np.array(temp_z4)\n",
    "    \n",
    "    #Plot them if requested:\n",
    "    if use_offset:\n",
    "        fig.add_trace(go.Scatter3d(x=temp_x3, y=temp_y3, z=temp_z3,\n",
    "                                   mode='markers',\n",
    "                                   marker={'color':'darkgray',\n",
    "                                           'symbol':'circle',\n",
    "                                           'size':6}))\n",
    "        if use_offsetvec:\n",
    "            fig.add_trace(go.Scatter3d(x=temp_x4, y=temp_y4, z=temp_z4,\n",
    "                                       mode='lines',\n",
    "                                       line={'width':2,\n",
    "                                             'color':'darkgray',\n",
    "                                             'dash':'dot'}))\n",
    "\n",
    "    #Draw a path that goes along every edge:\n",
    "    all_edge_vertpath = [0,1,3,0,5,3,2,4,3,5,4,6,5,7,6,8,7,0,9,7,8,9,1,10,8,11,10,2,11,4,6,11,10,9,1,2]\n",
    "    tri_x_alledges = tri_x[all_edge_vertpath]\n",
    "    tri_y_alledges = tri_y[all_edge_vertpath]\n",
    "    tri_z_alledges = tri_z[all_edge_vertpath]\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=tri_x_alledges, \n",
    "                               y=tri_y_alledges, \n",
    "                               z=tri_z_alledges,\n",
    "                               mode='lines',\n",
    "                               name='vertices',\n",
    "                               marker=dict(\n",
    "                                   size=12,\n",
    "                                   color=1,\n",
    "                                   opacity=1\n",
    "                               )\n",
    "                              ))\n",
    "\n",
    "    #Draw the bias vector:\n",
    "    if biasvec:\n",
    "        fig.add_trace(go.Scatter3d(x=[0,ov_big[0]],y=[0,ov_big[1]],z=[0,ov_big[2]],\n",
    "                                   text=['','Bias point'], \n",
    "                                   textposition='top center',\n",
    "                                   marker={'size':5,\n",
    "                                           'symbol':'diamond',\n",
    "                                           'color':'green',\n",
    "                                          }\n",
    "                                  ))\n",
    "\n",
    "\n",
    "    \n",
    "    #Build a vector to show frequency for each face (toss in \"None\"s\n",
    "    #between to split each vector from the next within a single scatter\n",
    "    #plot call):\n",
    "    \n",
    "    for n in range(20):\n",
    "        fig.add_trace(go.Scatter3d(x=[fv[n,0]*(scale_foffset+test_hist[n]*scale_facevec), fv[n,0]*scale_foffset],\n",
    "                                   y=[fv[n,1]*(scale_foffset+test_hist[n]*scale_facevec), fv[n,1]*scale_foffset],\n",
    "                                   z=[fv[n,2]*(scale_foffset+test_hist[n]*scale_facevec), fv[n,2]*scale_foffset],\n",
    "                                   mode='markers',\n",
    "                                   #mode='lines+markers',\n",
    "                                   #line={'width': 17,\n",
    "                                   #      'color': 'black',\n",
    "                                   #     },\n",
    "                                   marker={'size': 4,\n",
    "                                           'color': [test_hist[n]*scale_facevec,test_hist[n]*scale_facevec],\n",
    "                                           'colorscale': cmap,\n",
    "                                           'cmax': 2,\n",
    "                                           'cmin': 0,\n",
    "                                           'line':{'color':'black', 'width':4}\n",
    "                                          }\n",
    "                                  ))\n",
    "        fig.add_trace(go.Scatter3d(x=[fv[n,0]*(scale_foffset+test_hist[n]*scale_facevec), fv[n,0]*scale_foffset],\n",
    "                                   y=[fv[n,1]*(scale_foffset+test_hist[n]*scale_facevec), fv[n,1]*scale_foffset],\n",
    "                                   z=[fv[n,2]*(scale_foffset+test_hist[n]*scale_facevec), fv[n,2]*scale_foffset],\n",
    "                                   mode='lines+markers',\n",
    "                                   line={'width': 16,\n",
    "                                         'color': [test_hist[n]*scale_facevec,test_hist[n]*scale_facevec],\n",
    "                                         'colorscale': cmap,\n",
    "                                         'cmax': 2,\n",
    "                                         'cmin': 0\n",
    "                                        },\n",
    "                                   marker={'size': 3,\n",
    "                                           'color': [test_hist[n]*scale_facevec,test_hist[n]*scale_facevec],\n",
    "                                           'colorscale': cmap,\n",
    "                                           'cmax': 2,\n",
    "                                           'cmin': 0\n",
    "                                          }\n",
    "                                  ))\n",
    "    \n",
    "    #Label the faces, on the end of each scale vec:\n",
    "    labels_scalevec = 0.2 + scale_foffset+test_hist*scale_facevec\n",
    "    labelmin = 0.2 + scale_foffset+(len(dice_set)/20)*scale_facevec\n",
    "    labels_scalevec[labels_scalevec < labelmin] = labelmin\n",
    "    fig.add_trace(go.Scatter3d(x=fv[:,0]*labels_scalevec,\n",
    "                               y=fv[:,1]*labels_scalevec,\n",
    "                               z=fv[:,2]*labels_scalevec,\n",
    "                               text=num_str,\n",
    "                               textfont=dict(\n",
    "                                   family=\"sans serif\",\n",
    "                                   size=20,\n",
    "                                   color='darkblue'\n",
    "                               ),\n",
    "                               mode='text',\n",
    "                               textposition=\"middle center\"\n",
    "                              ))\n",
    "    \n",
    "    #     #Label the faces (on the face):\n",
    "    #     fig.add_trace(go.Scatter3d(x=fv[:,0]*1.1, y=fv[:,1]*1.1, z=fv[:,2]*1.1,\n",
    "    #                                text=num_str,\n",
    "    #                                textfont=dict(\n",
    "    #                                    family=\"sans serif\",\n",
    "    #                                    size=20,\n",
    "    #                                    color='darkblue'\n",
    "    #                                ),\n",
    "    #                                mode='text',\n",
    "    #                                textposition=\"middle center\"\n",
    "    #                               ))\n",
    "\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dice(test_dice.iloc[:,0], cmap='rdbu_r')\n",
    "# display_dice(test_dice_2.iloc[:-1,3])\n",
    "\n",
    "#Not bad, but the face vectors could be better. Maybe need an outline.\n",
    "\n",
    "#Also, should be uniform color for any spots that are within expected\n",
    "#variance. Only color up the ones outside it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "And stats-wise... looking at Dice 0, the bias vector is the little green thing (if \"biasvec\" input is set to True). It doesn't seem to be a helpful indicator of which faces have more rolls. Offsetting a sphere has the same problem. Either is *accurate*, but not very *useful*, because the dice is biased by face geometry, not weight. The edges are visibly less sharp around the opposite side from face 7. There is still enough bias toward one side that they do tell you something, like pointing away from the cold spot on Dice 0, but the displayed dice does better.\n",
    "\n",
    "Next steps: \n",
    "\n",
    "1) Use a sphere to display the likelihood instead of a dice? The smoothness might make the face bias and hot/cold spots a lot easier to see, and it would be a good chance to learn how to map and smooth data onto a surface.  \n",
    "2) Histogram sorted by frequency, compare to randomly-generated sets of rolls. This will be a good way to distinguish visually between random error and systematic bias. DONE, see below.\n",
    "\n",
    "So! Long story short, I am reasonably sure that dice 0 (the Orange dice) is somewhat biased, given the large difference between the sides, and the fact that there is a clear order to it. However, that order is not what I was expecting. It looks like there's a cold spot, but instead of the corresponding higher areas being on the opposite side from the cold spot (like you might expect if the dice was heavier on one side), the hottest spots are right around the edge. This suggests that rather than having a weight imbalance, it has an edge imbalance. Perhaps the edges around 7 (opposite 14), may be less pronounced. This would lead to the dice tending to continue rolling, rather than stopping with that face down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Known from dice:\n",
    "test_set_1 = test_dice.iloc[:,0]\n",
    "test_set_2 = test_dice.iloc[:,1]\n",
    "test_hist_1, test_bins = np.histogram(test_set_1, bins=np.arange(0.5,21.5))\n",
    "test_hist_2, test_bins = np.histogram(test_set_2, bins=test_bins)\n",
    "\n",
    "test_hist_1_inds = np.argsort(test_hist_1)\n",
    "test_hist_1 = np.sort(test_hist_1)\n",
    "test_hist_2_inds = np.argsort(test_hist_2)\n",
    "test_hist_2 = np.sort(test_hist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we have a set of histogram data that we want to get an average\n",
    "#between... what I should really do here is see whether the graphs\n",
    "#are comparable between the different roll-number scales\n",
    "\n",
    "all_testset.shape\n",
    "\n",
    "#This set is 100000x10x20, number of sets x which setsize (setsizes) x face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling based on my orange dice, get the potential range\n",
    "histrange = int(np.ceil(np.sum(test_hist_1) * 0.1))\n",
    "\n",
    "#For the test set, we want to sort so that the faces are ordered by\n",
    "#how often each one happened, not by number. The face number itself\n",
    "#is not relevant, since in this simulation they are equally likely.\n",
    "#We just want the likelihood that SOME face is higher or lower than\n",
    "#a given value. \n",
    "\n",
    "#Sort the testset by most-likely to least-likely face\n",
    "all_testset_sort = np.sort(all_testset, axis=2) #sort along face axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Re-histogram: Get histograms for each face for each nrolls\n",
    "\n",
    "# #Note: Sometimes true_divide warnings, since there are zeros,\n",
    "# #but it works fine.\n",
    "\n",
    "# target_set = 4\n",
    "# histset = []\n",
    "# #for each of 10 types of test set,\n",
    "# for n in range(10):\n",
    "#     histtemp = []\n",
    "#     #For each of 20 numbers,\n",
    "#     for m in range(20):\n",
    "#         #Generate the histogram for that number\n",
    "#         temporary_histogram, binstemp = np.histogram(all_testset_sort[:,n,m], bins=np.arange(0.5,histrange+1.5))\n",
    "#         histtemp.append(temporary_histogram/sum(temporary_histogram))\n",
    "#     histset.append(histtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = 0,0\n",
    "temporary_histogram, binstemp = np.histogram(all_testset_sort[:,n,m], bins=np.arange(0.5,histrange+1.5))\n",
    "# histtemp.append(temporary_histogram/sum(temporary_histogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_testset_sort[:,0,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dice_hist(dice_set, modeled_set, setsizes):\n",
    "    \n",
    "    #Process the dice data:\n",
    "    test_hist, test_bins = np.histogram(dice_set, bins=np.arange(0.5,21.5))\n",
    "    test_hist_inds = np.argsort(test_hist)\n",
    "    test_hist = np.sort(test_hist)\n",
    "    \n",
    "    #Set the max range on the histogram to half of total rolls:\n",
    "    histrange = int(np.ceil(np.sum(test_hist) * 0.5))\n",
    "    \n",
    "    #Build a test histogram that is scaled to the number of dice rolls:\n",
    "    nrolls = len(dice_set)\n",
    "    nsets = modeled_set.shape[0]\n",
    "    \n",
    "    test_hist_bulk = []\n",
    "    for n in range(numsets):\n",
    "        test_hist_bulk.append(all_testset[n,7,:])\n",
    "\n",
    "    test_hist_bulk = np.sort(np.array(test_hist_bulk).squeeze(),axis=1)\n",
    "    test_hist_out = []\n",
    "    for n in range(20):\n",
    "        temphist = np.histogram(test_hist_bulk[:,n], bins=np.arange(0.5,histrange+1.5))\n",
    "        test_hist_out.append(temphist[0])\n",
    "    \n",
    "    test_hist_model = []\n",
    "    for n in range(nsets):\n",
    "        test_hist_model.append(modeled_set[n,5,:])\n",
    "    test_hist_model = np.sort(np.array(test_hist_model).squeeze(),axis=1)\n",
    "    \n",
    "    test_hist_out = []\n",
    "    for n in range(20):\n",
    "        temphist = np.histogram(test_hist_bulk[:,n], bins=np.arange(0.5,histrange+1.5))\n",
    "        test_hist_out.append(temphist[0])\n",
    "\n",
    "    test_hist_out = np.array(test_hist_out).squeeze().astype(float)\n",
    "    test_hist_out_nans = np.copy(test_hist_out)\n",
    "    test_hist_out_nans[test_hist_out_nans==0] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=[10,10])\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(test_hist_out_nans.T/np.max(test_hist_out,axis=1) + np.tile(np.arange(0,20),[histrange,1]),'k')\n",
    "    ax.set_yticks(range(20))\n",
    "    ax.set_yticklabels(['Least common'] + ['']*18 + ['Most common'])\n",
    "    ax.set_ylabel('Dice face, after sorting by how often it appears')\n",
    "    ax.set_xlabel('How often each face appears in 10000 randomly generated rolls (blue = mean)')\n",
    "    ax.plot(np.array([test_hist_1, test_hist_1]), np.array([np.arange(0,20), np.arange(1,21)]), 'r')\n",
    "    temp_maxes = np.argmax(test_hist_out, axis=1)\n",
    "    temp_means = np.matmul(test_hist_out, np.arange(histrange))/np.nansum(test_hist_out, axis=1)\n",
    "    plt.plot(np.array([temp_means, temp_means]), np.array([np.arange(0,20), np.arange(1,21)]), 'b')\n",
    "    #Label by likelihood:\n",
    "    for n in range(20):\n",
    "        offset_var = test_hist_1[n] - temp_means[n]\n",
    "        offset_var = -1*histrange*(int(offset_var<0) - 0.25)*0.04\n",
    "        n_likelihood = np.sum(test_hist_out[n,:test_hist_1[n]])/np.sum(test_hist_out[n,:])\n",
    "        ax.text(test_hist_1[n] + offset_var, n+0.4, s='{0:.3f}'.format(n_likelihood))\n",
    "        ax.text(80, n+0.25, num_str[test_hist_1_inds[n]])\n",
    "\n",
    "    plt.title('Dice 0 verdict: Very unlikely, though still technically possible.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dice_hist(test_set_1, all_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testset[0,4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_testset[0,5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign appropriate comparisons based on number of rolls:\n",
    "numrolls = np.sum(test_hist_2)\n",
    "histrange = int(np.ceil(numrolls * 0.2)) #Set max to one fifth of total. \n",
    "\n",
    "test_hist_bulk = []\n",
    "for n in range(numsets):\n",
    "    test_hist_bulk.append(all_testset[n,7,:])\n",
    "    \n",
    "test_hist_bulk = np.sort(np.array(test_hist_bulk).squeeze(),axis=1)\n",
    "test_hist_out = []\n",
    "for n in range(20):\n",
    "    temphist = np.histogram(test_hist_bulk[:,n], bins=np.arange(0.5,histrange+1.5))\n",
    "    test_hist_out.append(temphist[0])\n",
    "    \n",
    "test_hist_out = np.array(test_hist_out).squeeze().astype(float)\n",
    "test_hist_out_nans = np.copy(test_hist_out)\n",
    "test_hist_out_nans[test_hist_out_nans==0] = np.nan\n",
    "\n",
    "#Do the actual comparison:\n",
    "plt.figure(figsize=[10,10])\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(test_hist_out_nans.T/np.max(test_hist_out,axis=1) + np.tile(np.arange(0,20),[histrange,1]),'k')\n",
    "ax.set_yticks(range(20))\n",
    "ax.set_yticklabels(['Least common'] + ['']*18 + ['Most common'])\n",
    "ax.set_ylabel('Dice face, after sorting by how often it appears')\n",
    "ax.set_xlabel('How often each face was rolled, across 100000 randomly generated sets of {0} rolls (blue = mean)'.format(numrolls))\n",
    "ax.plot(np.array([test_hist_2, test_hist_2]), np.array([np.arange(0,20), np.arange(1,21)]), 'r')\n",
    "temp_maxes = np.argmax(test_hist_out, axis=1)\n",
    "temp_means = np.matmul(test_hist_out, np.arange(histrange))/np.nansum(test_hist_out, axis=1)\n",
    "plt.plot(np.array([temp_means, temp_means]), np.array([np.arange(0,20), np.arange(1,21)]), 'b')\n",
    "#Label by likelihood:\n",
    "for n in range(20):\n",
    "    offset_var = test_hist_2[n] - temp_means[n]\n",
    "    offset_var = -1*histrange*(int(offset_var<0) - 0.25)*0.04\n",
    "    n_likelihood = np.sum(test_hist_out[n,:test_hist_2[n]])/np.sum(test_hist_out[n,:])\n",
    "    ax.text(test_hist_2[n] + offset_var, n+0.4, s='{0:.3f}'.format(n_likelihood))\n",
    "    ax.text(80, n+0.25, num_str[test_hist_2_inds[n]])\n",
    "    \n",
    "plt.title('Dice 1 verdict: Only slightly unlikely')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(temp_means,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_1.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(temp_means,'b', test_hist_1,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_out[test_hist_out==0] = np.nan\n",
    "plt.plot(test_hist_out[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_out[0:10,15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_out[0:10,15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([test_hist_1,test_hist_1,np.repeat(np.NaN,20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(np.arange(0,20),[3,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(zip(test_hist_1,test_hist_1,np.array(['NaN']*20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([test_hist_1,test_hist_1,np.repeat(np.NaN,20)])\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['']*18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_out.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
